ggplot(data=data4, aes(x=data4$Ano, y=data4$Valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Total do Tratamento") +
ggtitle("Valor Total do Tratamento por ano por Infarto Agudo do Miocardio")
options(scipen=100)
ggplot(data=data4, aes(x=data4$Ano, y=data4$Valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Total do Tratamento") +
ggtitle("Valor Total do Tratamento por ano por Infarto Agudo do Miocardio")
options(scipen=10)
ggplot(data=data4, aes(x=data4$Ano, y=data4$Valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Total do Tratamento") +
ggtitle("Valor Total do Tratamento por ano por Infarto Agudo do Miocardio")
ggplot(data=data1, aes(x=data1$Ano, y=data1$Internacoes)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Quantidade de Internações") +
ggtitle("Quantidade de Internações por ano por Infarto Agudo do Miocardio")
ggplot(data=data2, aes(x=data2$Ano, y=data2$Permanencia)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Média de dias das Internações") +
ggtitle("Quantidade média de dias das Internações por ano por Infarto Agudo do Miocardio")
ggplot(data=data1, aes(x=data1$Ano, y=data1$Internacoes)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Quantidade de Internações") +
ggtitle("Quantidade de Internações por ano por Infarto Agudo do Miocardio")
ggplot(data=data2, aes(x=data2$Ano, y=data2$Permanencia)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Média de dias das Internações") +
ggtitle("Quantidade média de dias das Internações por ano por Infarto Agudo do Miocardio")
ggplot(data=data3, aes(x=data3$Ano, y=data3$Obitos)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Quantidade de Óbitos") +
ggtitle("Quantidade de Óbitos por ano por Infarto Agudo do Miocardio")
ggplot(data=data4, aes(x=data4$Ano, y=data4$Valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Total do Tratamento") +
ggtitle("Valor Total do Tratamento por ano por Infarto Agudo do Miocardio")
citation()
sum(data4$Valor)
summary(data4)
sum(data1$Internacoes)
sum(data3$Obitos)
intVal <- sapply(data1$Ano ,data1$Internacoes/data4$Valor)
intVal <- c(data1$Ano ,data1$Internacoes/data4$Valor)
intVal
intVal <- table(data1$Ano ,data1$Internacoes/data4$Valor)
inverse.gaussian()
intVal
data1$Internacoes/data4$Valor
intVal <- table(data1$Ano ,data4$Valor/data1$Internacoes)
intVal
data4$Valor/data1$Internacoes
intVal <- table(data1$Ano, data4$Valor/data1$Internacoes)
intVal <- c(data1$Ano, data4$Valor/data1$Internacoes)
intVal
intVal$Ano <- data1$Ano
intVal$Ano <- data1$Ano
intVal$Ano
intVal$ValMed <- data4$Valor/data1$Internacoes
intVal
inVal$ValMed <- data4$Valor/data1$Internacoes
inVal$ValMed <- data4$Valor/data1$Internacoes
inVal$Ano <- data1$Ano
inVal$Ano <- data1$Ano
inVal$Ano <- data1$Ano
intVal
inVal
inVal$Ano <- c(data1$Ano)
inVal <- inVal$Ano
ano<-c(data1$Ano)
valInt<-data4$Valor/data1$Internacoes
valor<-data4$Valor/data1$Internacoes
intVal <- data.frame(ano,valor)
intVal
options(scipen=10000)
ggplot(data=intVal, aes(x=intVal$ano, y=intVal$valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Medio Gasto") +
ggtitle("Valor Medio do Tratamento por ano por Infarto Agudo do Miocardio")
library(ggplot2)
options(scipen=10000)
ggplot(data=intVal, aes(x=intVal$ano, y=intVal$valor)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Valor Medio Gasto") +
ggtitle("Valor Medio do Tratamento por ano por Infarto Agudo do Miocardio")
pOb <- data1$Internacoes/data3$Obitos
perOB <- data.frame(ano,pOb)
perOB
options(scipen=10000)
ggplot(data=perOB, aes(x=perOB$ano, y=perOB$pOb)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Óbitos") +
ggtitle("Valor Medio do Tratamento por ano por Infarto Agudo do Miocardio")
ggplot(data=perOB, aes(x=perOB$ano, y=perOB$pOb)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Óbitos") +
ggtitle("Relação Óbito por Internações por ano por Infarto Agudo do Miocardio")
ggplot(data=perOB, aes(x=perOB$ano, y=perOB$pOb)) +
geom_bar(stat="identity") + xlab("Ano") + ylab("Óbitos") +
ggtitle("Relação Internações por Óbito por ano por Infarto Agudo do Miocardio")
?str
?ToothGrowth
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
z <- x*w
mean(z)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
sum(x*w)/sum(w)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
sum(x*y)/sum(x^2)
data(mtcars)
x<-mtcars$wt
y<-mtcars$mpg
beta1<-cor(y,x)*sd(y)/sd(x)
coef(lm(mtcars$mpg~mtcars$wt))
sd(x)/sd(y)=0.5
cor(y,x)=0.5
Cor(Y, X)Sd(y)/Sd(x) = 0.5/0.5=1
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
miu <- mean(x)
S<-sd(x)
S
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
miu <- mean(x)
S<-sd(x)
(8.58 - miu)/S
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta1<-cor(y,x)*sd(y)/sd(x)
beta0<-mean(x) - beta1*mean(x)
coef(lm(y~x))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
beta1<- cor(y,x) * sd(y)/sd(x)
y1<-cor(x,y) * sd(x)/sd(y)
beta1/y1 = (sd(y)^2) / (sd(x)^2) = var(y) / var(x)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit<-lm(y~x)
summary(fit)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
# Give a P-value for the two sided hypothesis test of whether
# β1 from a linear regression model is 0 or not.
fit <- lm(y ~ x)
summary(fit)$coefficients
e <- resid(fit)
sqe <- e*e
res.var <- sum(sqe) / (length(e) - 2)
sqrt(res.var)
data(mtcars)
attach(mtcars)
fit <- lm(mpg ~ wt, mtcars)
summary(fit)
exp <- fit$coefficients[1] + mean(wt) * fit$coefficients[2]
exp - 2 * 0.5591
data(mtcars)
fit <- lm(mpg ~ wt, data = mtcars)
# Get a 95% confidence interval for the expected mpg at the average weight.
# What is the lower endpoint?
newdata <- data.frame(wt=mean(mtcars$wt))
predict(fit, newdata, interval = ("confidence"))[2]
data(mtcars)
fit <- lm(mpg ~ wt, data = mtcars)
summary(fit)
?mtcars
coef(fit)
data(mtcars)
fit <- lm(mpg ~ wt, data = mtcars)
newdata <- data.frame(wt=3)
predict(fit, newdata, interval = ('prediction'))[3]
summary(fit)
2 * (fit$coefficients[2] - 2 * 0.5591)
data(mtcars)
wtOvr2 <- mtcars$wt / 2
fit <- lm(mtcars$mpg ~ wtOvr2)
coef <- summary(fit)$coefficients
coef[2,1] - qt(.975, df = fit$df) * coef[2,2]
data(mtcars)
# About what is the ratio of the the sum of the squared errors
# when comparing a model with just an intercept (denominator)
y <- mtcars$mpg; x <- mtcars$wt; n <- length(y)
fit <- lm(y ~ x - 1)
beta1 <- summary(fit)$coefficients[1]
e <- y - beta1*x
sse1 <- sum(e^2)
# to the model with the intercept and slope (numerator)?
y <- mtcars$mpg; x <- mtcars$wt; n <- length(y)
beta1 <- cor(y, x) * sd(y) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
e <- y - beta0 - beta1 * x
sse2 <- sum(e^2)
# this is not what the question asked for (it asked for sse2/sse1)
# but hey, it worked
sqrt(sse2)/sqrt(sse1)
# with the intercept and slope (numerator)
fit<-lm(mpg~wt, data=mtcars)
e1<-resid(fit)
# just an intercept (denominator)
fit2<-lm(mpg~1, data=mtcars)
e2<-resid(fit2)
sum(e1^2)/sum(e2^2)
or
deviance(fit)/deviance(fit2)
plot(mpg~wt, data=mtcars,xlim=range(0,mtcars$wt), ylim=range(0,mtcars$mpg))
abline(lm(mpg~wt, data=mtcars),col="blue")  # with the intercept and slope
abline(lm(mpg~1, data=mtcars),col="red")  # just an intercept
abline(lm(mpg~wt-1, data=mtcars),col="green")  # remove an intercept, just slop
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
# Give a P-value for the two sided hypothesis test of whether
# β1 from a linear regression model is 0 or not.
fit <- lm(y ~ x)
summary(fit)$coefficients
?mtcars
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, mtcars)
summary(fit)
fit2 <- lm(mpg ~ factor(cyl), mtcars)
summary(fit2)
fit<-lm(mpg~factor(cyl)+wt, data=mtcars)
fit$coeff
fit2<-lm(mpg~factor(cyl), data=mtcars)
fit2$coeff
summary(fit)$cov
fit3 <- lm(mpg ~ factor(cyl)*wt, mtcars)
summary(fit3)
fit<-lm(mpg~factor(cyl)+wt, data=mtcars)
fit2<-update(fit, mpg~factor(cyl)+wt+factor(cyl)*wt)
anova(fit, fit2)
library(caret)
library(rpart)
library(tree)
library(randomForest)
library(e1071)
library(ggplot2)
?mtcars
cor(mtcars[, c(1, 6, 7, 9)])
?cor
pairs(mtcars[, c(1, 6, 7, 9)], panel = panel.smooth, col = 9 + mtcars$wt)
model1 <- lm(mpg ~ am, data=mtcars)
# II)Model 2
model2 <- step(model1, direction = "both")
# III)Anova
anova(model1, model2)
# I)Model 1
model1 <- lm(mpg ~ ., data=mtcars)
# II)Model 2
model2 <- step(model1, direction = "both")
# III)Model 3
model3 <- lm(mpg ~ am, data = mtcars)
# III)Anova
anova(model3, model2)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training) # OR
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
par(mfrow = c(2, 1), mar = c(4, 2, 2, 2))
hist(training$Superplasticizer, main = "")
hist(log(training$Superplasticizer + 1), main = "")
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() + theme_bw()
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) + geom_boxplot() + geom_jitter(col="blue") + theme_bw()
install.packages("Hmisc")
library(Hmisc)
cutCompressiveStrength <- cut2(training$CompressiveStrength, g=4)
summary(cutCompressiveStrength)
ggplot(data=training, aes(y=index, x=cutCompressiveStrength)) + geom_boxplot() + geom_jitter(col="blue") + theme_bw()
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(plyr)
splitOn <- cut2(training$Age, g=4)
splitOn <- mapvalues(splitOn,
from=levels(factor(splitOn)),
to=c("red", "blue", "yellow", "green"))
plot(training$CompressiveStrength, col=splitOn)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training) # OR
ggplot(data=training, aes(x=Superplasticizer)) + geom_histogram() + theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
et.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
acc1 <- C1$overall[1]
acc1 # Non-PCA Accuracy: 0.65
modelFit <- train(training$diagnosis ~ .,
method="glm",
preProcess="pca",
data=training,
trControl=trainControl(preProcOptions=list(thresh=0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
acc2 <- C2$overall[1]
acc2 # PCA Accuracy: 0.72
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p=3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
IL <- grep("^IL", colnames(training), value=TRUE)
ILpredictors <- predictors[, IL]
df <- data.frame(diagnosis, ILpredictors)
inTrain <- createDataPartition(df$diagnosis, p=3/4)[[1]]
training <- df[inTrain, ]
testing <- df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method="glm", data=training)
predictions <- predict(modelFit, newdata=testing)
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
install.packages("e1071")
library(e1071)
set.seed(3433)
## grep the predictors starting with 'IL'
IL_str <- grep("^IL", colnames(training), value = TRUE)
## make a subset of these predictors
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
## train the data using the first method
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
## get the confustion matrix for the first method
C1 <- confusionMatrix(predictions, testing$diagnosis)
print(C1)
A1 <- C1$overall[1]
## do similar steps with the caret package
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca",
data = training, trControl = trainControl(preProcOptions = list(thresh = 0.8)))
C2 <- confusionMatrix(testing$diagnosis, predict(modelFit, testing))
print(C2)
A2 <- C2$overall[1]
A2
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
IL_str <- grep("^IL", colnames(training), value = TRUE)
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc$rotation
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
install.packages("ElemStatLearn")
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
setwd("~/coursera/Communicating Data Science Results/datasci_course_materials/assignment6")
install.packages("scales")
install.packages("scales")
setwd("~/coursera/Communicating Data Science Results/datasci_course_materials/assignment6")
install.packages("scales")
install.packages("scales")
install.packages("scales")
?ggplot
?ggplot2
??ggplot2
install.packages("ggmap")
View(predictors_IL)
